# Workflow de Desarrollo - SDK Datadis

## [FLUJO] Flujo de Desarrollo Obligatorio

### **REGLA ORO: Test-First Development**
```
[PROHIBIDO] PROHIBIDO: CÃ³digo sin tests
[OBLIGATORIO] OBLIGATORIO: Tests antes de implementaciÃ³n
```

### Workflow EstÃ¡ndar:
```
1. [PLANIFICAR] Planificar feature/bugfix
2. [OK] Escribir tests PRIMERO
3. ðŸ”´ Verificar que tests fallan (TDD)
4. ðŸ’» Implementar cÃ³digo mÃ­nimo para pasar tests
5. [OK] Verificar que tests pasan
6. ðŸ”„ Refactorizar si necesario
7. [METRICAS] Ejecutar suite completa
8. [DOCUMENTAR] Code review + test review
9. [OK] Merge solo si 100% tests passing
```

## [ESTANDARES] EstÃ¡ndares de CÃ³digo

### **Formateo y Linting (OBLIGATORIO)**
```bash
# Antes de cada commit:
poetry run black datadis_python/
poetry run isort datadis_python/
poetry run flake8 datadis_python/
poetry run mypy datadis_python/

# O usar el script integrado:
python run_tests.py --quality
```

### **ConfiguraciÃ³n Black**
- 88 caracteres por lÃ­nea
- Target Python 3.8+
- Strings consistentes

### **ConfiguraciÃ³n isort**
- Perfil compatible con Black
- SeparaciÃ³n por categorÃ­as
- Imports ordenados alfabÃ©ticamente

### **ConfiguraciÃ³n flake8**
- Max line length: 88
- Ignores: E203, E501, W503, F401, F541, E402
- Focus en errores lÃ³gicos

### **MyPy Type Checking**
- Python 3.8 compatible
- Strict mode habilitado
- `typing-extensions` para retrocompatibilidad

## [NOMENCLATURA] Convenciones de Nomenclatura

### **Python Code Style**
```python
# Clases: PascalCase
class DatadisClient:
class ConsumptionData:

# MÃ©todos y funciones: snake_case
def get_consumption():
def validate_cups():

# Constantes: UPPER_SNAKE_CASE
API_V1_ENDPOINTS = {}
DEFAULT_TIMEOUT = 30

# Variables privadas: _leading_underscore
def _make_authenticated_request():
self._token = None
```

### **Archivos y Directorios**
```
# Archivos: snake_case
simple_client.py
text_utils.py
consumption.py

# Directorios: snake_case
client/v1/
utils/
models/
```

## [TESTING] EstÃ¡ndares de Testing

### **Marcadores Obligatorios**
```python
@pytest.mark.unit          # Tests unitarios rÃ¡pidos
@pytest.mark.integration   # Tests de integraciÃ³n
@pytest.mark.slow         # Tests que toman >5 segundos
@pytest.mark.auth         # Tests de autenticaciÃ³n
@pytest.mark.models       # Tests de modelos Pydantic
@pytest.mark.client_v1    # Tests especÃ­ficos V1
@pytest.mark.client_v2    # Tests especÃ­ficos V2
@pytest.mark.utils        # Tests de utilidades
@pytest.mark.errors       # Tests de manejo de errores
```

### **Naming Convention Tests**
```python
# Estructura obligatoria
def test_[component]_[scenario]_[expected_result]():
    """DescripciÃ³n clara del test."""

# Ejemplos:
def test_validate_cups_valid_format_returns_uppercase():
def test_client_authentication_empty_response_raises_error():
def test_consumption_model_invalid_data_raises_validation_error():
```

### **Estructura de Test**
```python
def test_feature():
    """DescripciÃ³n clara de quÃ© se prueba."""
    # Arrange: Preparar datos/mocks
    client = SimpleDatadisClientV1(username="test", password="test")

    # Act: Ejecutar acciÃ³n
    result = client.method()

    # Assert: Verificar resultados
    assert isinstance(result, ExpectedType)
    assert result.property == expected_value
```

## [COMANDOS] Comandos de Desarrollo

### **Testing Durante Desarrollo**
```bash
# Tests rÃ¡pidos (dÃ­a a dÃ­a)
python run_tests.py --fast

# Tests de componente especÃ­fico
python run_tests.py --component auth
python run_tests.py --component models
python run_tests.py --component client_v1

# Test especÃ­fico con debug
poetry run pytest tests/test_file.py::test_method -v -s

# Tests con coverage
python run_tests.py --coverage
```

### **ValidaciÃ³n Pre-Commit**
```bash
# Calidad de cÃ³digo
python run_tests.py --quality

# Suite completa
python run_tests.py --all

# Solo si todo pasa â†’ commit
```

### **Debugging y Desarrollo**
```bash
# Tests con output detallado
poetry run pytest -v -s

# Tests con breakpoints
poetry run pytest --pdb

# Coverage especÃ­fico
poetry run pytest --cov=datadis_python/models tests/test_models.py
```

## [CONFIGURACION] ConfiguraciÃ³n del Entorno

### **Poetry Setup**
```bash
# Instalar dependencias de desarrollo
poetry install --with dev

# Activar shell
poetry shell

# Agregar nueva dependencia
poetry add requests pydantic

# Agregar dependencia de desarrollo
poetry add --group dev pytest black mypy
```

### **Pre-commit Hooks (Recomendado)**
```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: tests-fast
        name: Fast Tests
        entry: python run_tests.py --fast
        language: system
        pass_filenames: false

      - id: quality-checks
        name: Quality Checks
        entry: python run_tests.py --quality
        language: system
        pass_filenames: false
```

## [PROCESO] Proceso de Code Review

### **Checklist para el Autor**
- [ ] [OK] Tests escritos ANTES de implementaciÃ³n
- [ ] [OK] Todos los tests pasan localmente
- [ ] [OK] Calidad de cÃ³digo validada (black, flake8, mypy)
- [ ] [OK] DocumentaciÃ³n actualizada si necesario
- [ ] [OK] Sin cÃ³digo comentado o debug prints
- [ ] [OK] Nombres descriptivos y claros

### **Checklist para el Reviewer**
- [ ] [TESTING] Â¿Tests cubren casos felices y edge cases?
- [ ] [SEGURIDAD] Â¿Manejo de errores es apropiado?
- [ ] ðŸ“ Â¿Sigue patrones arquitecturales del SDK?
- [ ] [MANTENIMIENTO] Â¿Es mantenible y extensible?
- [ ] [DOCUMENTACION] Â¿DocumentaciÃ³n es clara?
- [ ] âš¡ Â¿Performance es aceptable?

## [DEFINICION] DefiniciÃ³n de "Done"

### **Para Features Nuevas**
- [ ] [OK] Tests unitarios + integraciÃ³n escritos
- [ ] [OK] Tests pasan en mÃºltiples entornos
- [ ] [OK] DocumentaciÃ³n actualizada
- [ ] [OK] Code review aprobado
- [ ] [OK] Sin regresiones en suite existente
- [ ] [OK] Performance aceptable

### **Para Bug Fixes**
- [ ] [OK] Test que reproduce el bug
- [ ] [OK] Fix implementado
- [ ] [OK] Test pasa despuÃ©s del fix
- [ ] [OK] Sin efectos secundarios
- [ ] [OK] Root cause documentado

### **Para Refactoring**
- [ ] [OK] Todos los tests existentes siguen pasando
- [ ] [OK] No hay cambios en API pÃºblica
- [ ] [OK] Performance mantenida o mejorada
- [ ] [OK] CÃ³digo mÃ¡s limpio/mantenible

## [POLITICAS] PolÃ­ticas de Calidad

### **Tolerancia Cero**
```
[PROHIBIDO] NUNCA permitir:
- Tests fallando en main branch
- CÃ³digo sin tests
- Commits que rompan la build
- Secrets/keys en cÃ³digo
- CÃ³digo comentado en production
```

### **MÃ©tricas MÃ­nimas**
```
[REQUERIDO] REQUERIDO mantener:
- Test coverage: >90%
- Test pass rate: 100%
- Type coverage: >80%
- Performance: Tests <60s total
```

### **Dependencias**
```python
# Solo dependencias necesarias
# Evaluar impacto antes de agregar
# Mantener actualizadas (security)
# Documentar razÃ³n de inclusiÃ³n
```

## [METRICAS] MÃ©tricas y Monitoring

### **CI/CD Checks**
- [OK] Tests unitarios + integraciÃ³n
- [OK] Calidad de cÃ³digo (black, flake8, mypy)
- [OK] Security scan de dependencias
- [OK] Coverage report
- [OK] Performance regression tests

### **Release Checklist**
- [ ] [METRICAS] Todos los tests pasan
- [ ] [DOCUMENTACION] CHANGELOG actualizado
- [ ] [VERSION] Version bump apropiado (semver)
- [ ] ðŸ“š DocumentaciÃ³n actualizada
- [ ] ðŸ”’ Security review completado
- [ ] âš¡ Performance validada

---

**Este workflow asegura**:
- [OK] **Calidad**: CÃ³digo robusto y bien probado
- [OK] **Mantenibilidad**: EstÃ¡ndares consistentes
- [OK] **ColaboraciÃ³n**: Proceso claro para el equipo
- [OK] **Confiabilidad**: Sin regresiones o bugs
- [OK] **Velocidad**: Desarrollo eficiente con buen tooling
